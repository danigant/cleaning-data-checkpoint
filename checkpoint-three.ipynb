{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
            },
            "source": [
                "# Checkpoint Three: Cleaning Data\n",
                "\n",
                "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
                "\n",
                "My dataset:\n",
                "\n",
                "Import the necessary libraries and create your dataframe(s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 215,
            "metadata": {
                "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib import style\n",
                "\n",
                "#Setting up dataframes\n",
                "titles_df = pd.read_csv(\"titles-to-clean.csv\")\n",
                "credits_df = pd.read_csv(\"credits-to-clean.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
            },
            "source": [
                "## Missing Data\n",
                "\n",
                "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 216,
            "metadata": {
                "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 66393 entries, 0 to 66392\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column     Non-Null Count  Dtype \n",
                        "---  ------     --------------  ----- \n",
                        " 0   person_id  66393 non-null  int64 \n",
                        " 1   id         66393 non-null  object\n",
                        " 2   name       66393 non-null  object\n",
                        " 3   role       66393 non-null  object\n",
                        "dtypes: int64(1), object(3)\n",
                        "memory usage: 2.0+ MB\n"
                    ]
                }
            ],
            "source": [
                "# For the Credits database, characters column contains a significant number of missing values. I do not plan on using this for my purposes anyway so I will be removing \n",
                "# the entire column\n",
                "credits_df = credits_df.drop(\"character\", axis=1)\n",
                "credits_df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above information displays that the Character column has been removed from the Credits DataFrame. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 3188 entries, 0 to 3293\n",
                        "Data columns (total 15 columns):\n",
                        " #   Column                Non-Null Count  Dtype  \n",
                        "---  ------                --------------  -----  \n",
                        " 0   id                    3188 non-null   object \n",
                        " 1   title                 3188 non-null   object \n",
                        " 2   type                  3188 non-null   object \n",
                        " 3   description           3185 non-null   object \n",
                        " 4   release_year          3188 non-null   int64  \n",
                        " 5   age_certification     2064 non-null   object \n",
                        " 6   runtime               3188 non-null   int64  \n",
                        " 7   genres                3188 non-null   object \n",
                        " 8   production_countries  3188 non-null   object \n",
                        " 9   seasons               730 non-null    float64\n",
                        " 10  imdb_id               2943 non-null   object \n",
                        " 11  imdb_score            2922 non-null   float64\n",
                        " 12  imdb_votes            2911 non-null   float64\n",
                        " 13  tmdb_popularity       3168 non-null   float64\n",
                        " 14  tmdb_score            3026 non-null   float64\n",
                        "dtypes: float64(5), int64(2), object(8)\n",
                        "memory usage: 398.5+ KB\n"
                    ]
                }
            ],
            "source": [
                "# I am going to clean up any row that is missing both IMDb and TMDb score values since most of my business questions rely on these data points.\n",
                "titles_df = titles_df.dropna(subset=['imdb_score', 'tmdb_score'], how='all')\n",
                "titles_df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The information above displays that 106 rows were removed from the Titles DataFrame. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 3188 entries, 0 to 3293\n",
                        "Data columns (total 14 columns):\n",
                        " #   Column                Non-Null Count  Dtype  \n",
                        "---  ------                --------------  -----  \n",
                        " 0   id                    3188 non-null   object \n",
                        " 1   title                 3188 non-null   object \n",
                        " 2   type                  3188 non-null   object \n",
                        " 3   release_year          3188 non-null   int64  \n",
                        " 4   age_certification     2064 non-null   object \n",
                        " 5   runtime               3188 non-null   int64  \n",
                        " 6   genres                3188 non-null   object \n",
                        " 7   production_countries  3188 non-null   object \n",
                        " 8   seasons               730 non-null    float64\n",
                        " 9   imdb_id               2943 non-null   object \n",
                        " 10  imdb_score            2922 non-null   float64\n",
                        " 11  imdb_votes            2911 non-null   float64\n",
                        " 12  tmdb_popularity       3168 non-null   float64\n",
                        " 13  tmdb_score            3026 non-null   float64\n",
                        "dtypes: float64(5), int64(2), object(7)\n",
                        "memory usage: 373.6+ KB\n"
                    ]
                }
            ],
            "source": [
                "# Next I am dropping the Description column from Titles. This column contains null values and plus I will not be using this data.\n",
                "titles_df = titles_df.drop(\"description\", axis=1)\n",
                "titles_df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The Description column has successfully been removed from the Titles DataFrame."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "age_certification\n",
                            "Unrated    1124\n",
                            "R           595\n",
                            "PG-13       469\n",
                            "TV-MA       311\n",
                            "PG          297\n",
                            "TV-14       143\n",
                            "G            83\n",
                            "TV-PG        83\n",
                            "TV-Y7        41\n",
                            "TV-G         20\n",
                            "TV-Y         15\n",
                            "NC-17         7\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 219,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# There are many null values in the Age Certification column. I do not want to drop these rows, so I will be replacing the NaN value with \"Unrated\". This way I will \n",
                "# still be able to perform analysis with this information and I will simply be creating a new category type for this column.\n",
                "titles_df[\"age_certification\"] = titles_df[\"age_certification\"].fillna(\"Unrated\")\n",
                "titles_df[\"age_certification\"].isna().sum()\n",
                "titles_df[\"age_certification\"].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are no longer any missing values in the Age Certification column and the null values have now been replaced with Unrated."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 220,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "type\n",
                            "MOVIE    2458\n",
                            "SHOW        0\n",
                            "Name: seasons, dtype: int64"
                        ]
                    },
                    "execution_count": 220,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# There are many missing values in the Seasons column, but I am wondering if most of these null values are because it is a Movie Title and not a TV Show. \n",
                "# I am going to check to see how many null values are present if the title is a TV Show.\n",
                "missing_TV_season = titles_df.groupby(\"type\")[\"seasons\"].apply(lambda x : x.isnull().sum())\n",
                "missing_TV_season"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above output shows that the missing data in the Seasons column is in fact because that title is a Movie and not a TV Show. I will not be removing or changing \n",
                "these values in this case. If I want to use the seasons column, I will filter it and null values will no longer be an issue."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 221,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "id                         0\n",
                            "title                      0\n",
                            "type                       0\n",
                            "release_year               0\n",
                            "age_certification          0\n",
                            "runtime                    0\n",
                            "genres                     0\n",
                            "production_countries       0\n",
                            "seasons                 2458\n",
                            "imdb_id                  245\n",
                            "imdb_score               266\n",
                            "imdb_votes               277\n",
                            "tmdb_popularity           20\n",
                            "tmdb_score               162\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 221,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# I want to take a look at how many more missing values there are besides in the Seasons column.\n",
                "titles_df.isna().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The remaining missing values are in the IMDb and TMDb categories. I do not want to make any changes to these currently, because I do not want to skew any results\n",
                "by replacing the null with a new value. I will leave them as is for now and decide how to proceed with them during my manipulation phase."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
            },
            "source": [
                "## Irregular Data\n",
                "\n",
                "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 222,
            "metadata": {
                "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "19\n"
                    ]
                }
            ],
            "source": [
                "# I can see from a scatter chart in my EDA that there are several titles that have IMDb votes that are over 1,000,000. I want to see how many exactly there are.\n",
                "title_count = []\n",
                "for i in (\"title\"):\n",
                "    title_count = (titles_df[\"imdb_votes\"] > 1000000).sum()\n",
                "print(title_count)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 223,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "count    2.911000e+03\n",
                            "mean     6.461835e+04\n",
                            "std      1.754617e+05\n",
                            "min      5.000000e+00\n",
                            "25%      9.245000e+02\n",
                            "50%      8.071000e+03\n",
                            "75%      4.764500e+04\n",
                            "max      2.555504e+06\n",
                            "Name: imdb_votes, dtype: float64"
                        ]
                    },
                    "execution_count": 223,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "titles_df[\"imdb_votes\"].describe()\n",
                "# There is a pretty wide spread of vote counts from IMDb, but I do feel like more popular titles will have more votes. During my EDA I do think higher vote counts\n",
                "# correlated with higher IMDb scores."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I have decided not to remove these outliers. I want to investigate popularity of titles and a title having an excess of votes just tells me that it is in fact popular. I am not sure if I will be looking at data based on the number of votes moving forward, so I do not want to remove these titles when their score info will be relevant to my research and vote count may not be. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
            },
            "source": [
                "## Unnecessary Data\n",
                "\n",
                "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I have already removed several columns of unnecessary data. In the Titles DataFrame I have removed the Description column and in the Credits DataFrame I have removed the Characters column. I will now be taking a look at the DataFrames and seeing if there are any rows or more columns that I would like to remove."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "metadata": {
                "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
            },
            "outputs": [],
            "source": [
                "# I am not going to be using any actor data from the Credits DataFrame, so I will be removing all of those rows.\n",
                "credits_to_keep = credits_df[\"role\"] == \"DIRECTOR\"\n",
                "credits_df = credits_df[credits_to_keep]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 225,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 2774 entries, 22 to 66392\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column     Non-Null Count  Dtype \n",
                        "---  ------     --------------  ----- \n",
                        " 0   person_id  2774 non-null   int64 \n",
                        " 1   id         2774 non-null   object\n",
                        " 2   name       2774 non-null   object\n",
                        " 3   role       2774 non-null   object\n",
                        "dtypes: int64(1), object(3)\n",
                        "memory usage: 108.4+ KB\n"
                    ]
                }
            ],
            "source": [
                "credits_df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The Credits DataFrame has now been reduced to 2774 rows from 66,393."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 226,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 3188 entries, 0 to 3293\n",
                        "Data columns (total 13 columns):\n",
                        " #   Column                Non-Null Count  Dtype  \n",
                        "---  ------                --------------  -----  \n",
                        " 0   id                    3188 non-null   object \n",
                        " 1   title                 3188 non-null   object \n",
                        " 2   type                  3188 non-null   object \n",
                        " 3   release_year          3188 non-null   int64  \n",
                        " 4   age_certification     3188 non-null   object \n",
                        " 5   runtime               3188 non-null   int64  \n",
                        " 6   genres                3188 non-null   object \n",
                        " 7   production_countries  3188 non-null   object \n",
                        " 8   seasons               730 non-null    float64\n",
                        " 9   imdb_score            2922 non-null   float64\n",
                        " 10  imdb_votes            2911 non-null   float64\n",
                        " 11  tmdb_popularity       3168 non-null   float64\n",
                        " 12  tmdb_score            3026 non-null   float64\n",
                        "dtypes: float64(5), int64(2), object(6)\n",
                        "memory usage: 348.7+ KB\n"
                    ]
                }
            ],
            "source": [
                "# I do not have a use for the IMDb ID column in the Titles DataFrame, so I will be dropping this column.\n",
                "titles_df = titles_df.drop(\"imdb_id\", axis=1)\n",
                "titles_df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "IMDb ID column has been successfully dropped from the Titles DataFrame."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
            },
            "source": [
                "## Inconsistent Data\n",
                "\n",
                "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 227,
            "metadata": {
                "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "XG not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "XC not found in ISO2\n",
                        "XC not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "XC not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "SU not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "XX not found in ISO2\n",
                        "XX not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "XX not found in ISO2\n",
                        "XX not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "XX not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "XX not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "XX not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "XX not found in ISO2\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n",
                        "Unknown not found in regex\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "production_countries\n",
                            "United States                    2036\n",
                            "United Kingdom                    144\n",
                            "Japan                             128\n",
                            "Unknown                            85\n",
                            "United Kingdom, United States      64\n",
                            "                                 ... \n",
                            "Spain, Argentina                    1\n",
                            "France, Spain                       1\n",
                            "Belgium, France, Guatemala          1\n",
                            "TÃ¼rkiye                             1\n",
                            "Panama                              1\n",
                            "Name: count, Length: 264, dtype: int64"
                        ]
                    },
                    "execution_count": 227,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# The production countries are all listed as 2 letter codes, but I would like to see what the full names of these countries are. I will be replacing the codes with \n",
                "# their full names, but first I will be replacing the [] values with \"Unknown\".\n",
                "titles_df[\"production_countries\"] = titles_df[\"production_countries\"].replace(\"[]\", \"Unknown\")\n",
                "\n",
                "# Next I need to remove the brackets and quotes from each of the country codes.\n",
                "titles_df[\"production_countries\"] = titles_df[\"production_countries\"].str.replace(\"[\",\"\")\n",
                "titles_df[\"production_countries\"] = titles_df[\"production_countries\"].str.replace(\"]\",\"\")\n",
                "titles_df[\"production_countries\"] = titles_df[\"production_countries\"].str.replace(\"'\",\"\")\n",
                "\n",
                "#There are so many different country codes that I will be using the country_converter library to convert the codes to full country names.\n",
                "import country_converter as coco       \n",
                "cc = coco.CountryConverter()\n",
                "\n",
                "# There are some production countries that list multiple countries per title, so I will need to split these up and convert each code individually.\n",
                "def convert_comma_separated_codes(code_string):\n",
                "    codes_list = [code.strip() for code in code_string.split(',')]\n",
                "    \n",
                "    # Convert the list of codes using country_converter,'not found' codes will be changed to 'Unknown'.\n",
                "    names_list = cc.convert(names=codes_list, to='name_short', not_found='Unknown')\n",
                "    \n",
                "    if isinstance(names_list, str):\n",
                "        names_list = [names_list]\n",
                "        \n",
                "    # Join the converted names back into a single comma-separated string\n",
                "    return ', '.join(names_list)\n",
                "\n",
                "titles_df['production_countries'] = titles_df['production_countries'].apply(convert_comma_separated_codes)\n",
                "titles_df[\"production_countries\"].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 228,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "np.int64(3188)"
                        ]
                    },
                    "execution_count": 228,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "titles_df[\"production_countries\"].value_counts().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "All production countries have all been changed to their full country names, with codes that were not found in the country converter now listed as Unknown."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 229,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "genres\n",
                            "documentation                      328\n",
                            "drama                              180\n",
                            "comedy                             178\n",
                            "comedy, documentation               60\n",
                            "comedy, drama                       50\n",
                            "                                  ... \n",
                            "documentation, music, history        1\n",
                            "drama, family, comedy                1\n",
                            "animation, action, fantasy           1\n",
                            "thriller, family, comedy, drama      1\n",
                            "thriller, romance, crime             1\n",
                            "Name: count, Length: 1127, dtype: int64"
                        ]
                    },
                    "execution_count": 229,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# The genre column contains several different genres per title and they are all listed with brackets and quotes. I will be removing these.\n",
                "titles_df[\"genres\"] = titles_df[\"genres\"].str.replace(\"[\",\"\")\n",
                "titles_df[\"genres\"] = titles_df[\"genres\"].str.replace(\"]\",\"\")\n",
                "titles_df[\"genres\"] = titles_df[\"genres\"].str.replace(\"'\",\"\")   \n",
                "titles_df[\"genres\"].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "All genres have now had the brackets and quotations removed. I will now be exporting out my new cleaned CSVs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 230,
            "metadata": {},
            "outputs": [],
            "source": [
                "titles_df.to_csv(\"clean_titles.csv\")\n",
                "credits_df.to_csv(\"clean_credits.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
            },
            "source": [
                "## Summarize Your Results\n",
                "\n",
                "Make note of your answers to the following questions.\n",
                "\n",
                "1. Did you find all four types of dirty data in your dataset?\n",
                "\n",
                "I do not believe I truly found any Irregular data. I did do a check on some data that could be an outliers if I was using this data set in a different way, but for my purposes I did not need to removing any data that would be considered an outlier. I did find many missing values, I removed unnecessary data columns and rows, and I changed formatting in a couple of columns.\n",
                "\n",
                "2. Did the process of cleaning your data give you new insights into your dataset?\n",
                "\n",
                "Now that I have cleaned these data sets, I do feel much more acquanited with the data and it helped me make some decisions in regards to how I would like to manipulate and what insights I will be planning on looking at.\n",
                "\n",
                "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
                "\n",
                "I feel like I have a pretty decent plan on how I would like to manipulate and visualize this data set. I will be mostly looking at different factors that may have influenced higher or lower scoring from audience rating sites."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
